{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ddfd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Generating Synthetic SDG 13 Data ---\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "clip() got an unexpected keyword argument 'min'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     32\u001b[39m df = pd.DataFrame(data)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Generate Target Variable: CO2 Emissions (kt)\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# The formula simulates the relationship: CO2 = f(GDP, Population, Fossil Fuel %) + noise\u001b[39;00m\n\u001b[32m     36\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mCO2_Emissions_kt\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGDP_per_capita\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m1.2e-4\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPopulation_Total\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m50000\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFossil_Fuel_Pct\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m=\u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset Head:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdf.head()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDataset Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\morgan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:9084\u001b[39m, in \u001b[36mNDFrame.clip\u001b[39m\u001b[34m(self, lower, upper, axis, inplace, **kwargs)\u001b[39m\n\u001b[32m   9077\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m ctr <= ref_count:\n\u001b[32m   9078\u001b[39m             warnings.warn(\n\u001b[32m   9079\u001b[39m                 _chained_assignment_warning_method_msg,\n\u001b[32m   9080\u001b[39m                 \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m   9081\u001b[39m                 stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   9082\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m9084\u001b[39m axis = \u001b[43mnv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_clip_with_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   9085\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9086\u001b[39m     axis = \u001b[38;5;28mself\u001b[39m._get_axis_number(axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\morgan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\compat\\numpy\\function.py:206\u001b[39m, in \u001b[36mvalidate_clip_with_axis\u001b[39m\u001b[34m(axis, args, kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"None\",\u001b[39;00m\n\u001b[32m    203\u001b[39m     \u001b[38;5;66;03m# variable has type \"Union[ndarray[Any, Any], str, int]\")\u001b[39;00m\n\u001b[32m    204\u001b[39m     axis = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[43mvalidate_clip\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[ndarray[Any, Any],\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# str, int]\", expected \"Union[str, int, None]\")\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m axis\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\morgan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\compat\\numpy\\function.py:88\u001b[39m, in \u001b[36mCompatValidator.__call__\u001b[39m\u001b[34m(self, args, kwargs, fname, max_fname_arg_count, method)\u001b[39m\n\u001b[32m     86\u001b[39m     validate_kwargs(fname, kwargs, \u001b[38;5;28mself\u001b[39m.defaults)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[43mvalidate_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fname_arg_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefaults\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minvalid validation method \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\morgan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\util\\_validators.py:223\u001b[39m, in \u001b[36mvalidate_args_and_kwargs\u001b[39m\u001b[34m(fname, args, kwargs, max_fname_arg_count, compat_args)\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    219\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() got multiple values for keyword argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    220\u001b[39m         )\n\u001b[32m    222\u001b[39m kwargs.update(args_dict)\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m \u001b[43mvalidate_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\morgan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\util\\_validators.py:164\u001b[39m, in \u001b[36mvalidate_kwargs\u001b[39m\u001b[34m(fname, kwargs, compat_args)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03mChecks whether parameters passed to the **kwargs argument in a\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03mfunction `fname` are valid parameters as specified in `*compat_args`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    161\u001b[39m \u001b[33;03mmap to the default values specified in `compat_args`\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    163\u001b[39m kwds = kwargs.copy()\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m \u001b[43m_check_for_invalid_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m _check_for_default_values(fname, kwds, compat_args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\morgan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\util\\_validators.py:138\u001b[39m, in \u001b[36m_check_for_invalid_keys\u001b[39m\u001b[34m(fname, kwargs, compat_args)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[32m    137\u001b[39m     bad_arg = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(diff))\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() got an unexpected keyword argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbad_arg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: clip() got an unexpected keyword argument 'min'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style for better visualization\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "# --- 1. DATASET SIMULATION (Replacing real data loading) ---\n",
    "# In a real scenario, you would load data from a CSV or API.\n",
    "print(\"--- 1. Generating Synthetic SDG 13 Data ---\")\n",
    "np.random.seed(42)\n",
    "N_SAMPLES = 1000\n",
    "COUNTRIES = ['USA', 'CHN', 'IND', 'DEU', 'BRA', 'NGA']\n",
    "\n",
    "# Generate features\n",
    "data = {\n",
    "    'Country': np.random.choice(COUNTRIES, N_SAMPLES),\n",
    "    'Year': np.random.randint(2000, 2020, N_SAMPLES),\n",
    "    # FIX APPLIED: Using positional argument 1000 for the lower bound instead of min=1000\n",
    "    'GDP_per_capita': np.random.normal(30000, 25000, N_SAMPLES).clip(1000),\n",
    "    'Population_Total': np.random.normal(50_000_000, 100_000_000, N_SAMPLES).clip(100_000),\n",
    "    'Fossil_Fuel_Pct': np.random.uniform(50, 95, N_SAMPLES),\n",
    "    'Industrial_Output_Index': np.random.normal(120, 30, N_SAMPLES)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generate Target Variable: CO2 Emissions (kt)\n",
    "# The formula simulates the relationship: CO2 = f(GDP, Population, Fossil Fuel %) + noise\n",
    "df['CO2_Emissions_kt'] = (\n",
    "    0.05 * df['GDP_per_capita'] +\n",
    "    1.2e-4 * df['Population_Total'] +\n",
    "    50000 * (df['Fossil_Fuel_Pct'] / 100) +\n",
    "    np.random.normal(0, 50000, N_SAMPLES)\n",
    "# FIX APPLIED: Using positional argument 10000 for the lower bound instead of min=10000\n",
    ").clip(10000)\n",
    "\n",
    "print(f\"Dataset Head:\\n{df.head()}\")\n",
    "print(f\"\\nDataset Shape: {df.shape}\")\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop('CO2_Emissions_kt', axis=1)\n",
    "y = df['CO2_Emissions_kt']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "# --- 2. PREPROCESSING PIPELINE ---\n",
    "print(\"\\n--- 2. Setting Up Preprocessing Pipeline ---\")\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['Country']\n",
    "numerical_features = ['GDP_per_capita', 'Population_Total', 'Fossil_Fuel_Pct', 'Industrial_Output_Index']\n",
    "\n",
    "# Create preprocessors for different feature types\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create a ColumnTransformer to apply the correct transformation to the correct columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features + ['Year']),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "# --- 3. MODEL BUILDING (Pipeline Integration) ---\n",
    "print(\"\\n--- 3. Building and Training Model Pipeline (Random Forest Regressor) ---\")\n",
    "\n",
    "# Create the full pipeline: Preprocessor -> Model\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "# --- 4. EVALUATION ---\n",
    "print(\"\\n--- 4. Model Evaluation ---\")\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:,.2f} kt\")\n",
    "print(f\"R-squared (R2) Score: {r2:.4f}\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "# --- 5. VISUALIZATION and INTERPRETATION (Feature Importance) ---\n",
    "print(\"\\n--- 5. Visualization and Interpretation ---\")\n",
    "\n",
    "# A. Actual vs. Predicted Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Create a DataFrame for plotting clarity\n",
    "results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "sns.scatterplot(x='Actual', y='Predicted', data=results_df, alpha=0.6)\n",
    "# Plot the ideal prediction line (y=x)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Ideal Prediction')\n",
    "plt.title('Actual vs. Predicted CO2 Emissions (kt) - SDG 13 Forecast')\n",
    "plt.xlabel('Actual CO2 Emissions (kt)')\n",
    "plt.ylabel('Predicted CO2 Emissions (kt)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# B. Feature Importance Plot\n",
    "rf_model = model_pipeline.named_steps['regressor']\n",
    "\n",
    "# Get feature names after one-hot encoding\n",
    "feature_names = (\n",
    "    numerical_features + ['Year'] +\n",
    "    list(model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
    ")\n",
    "\n",
    "# Create a DataFrame for importance\n",
    "feature_importances = pd.Series(rf_model.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=feature_importances.head(10).values, y=feature_importances.head(10).index, palette=\"viridis\")\n",
    "plt.title('Top 10 Feature Importance for CO2 Emission Prediction')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379bd23",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load the MNIST dataset\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
